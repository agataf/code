{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation learning for multilayer perceptron\n",
    "# with minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using MNIST, Plots\n",
    "gr(                        # GR backend for Plots\n",
    "    size = (600,600),    # you may need to change the numbers to fit your screen\n",
    "    legend = :none\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f(x) = tanh(x)\n",
    "df(y) = 1.0 - y.*y\n",
    "\n",
    "#f(x) = 1.0./(1.0+exp(-x))       # logistic function\n",
    "#df(y) = y.*(1.0-y)\n",
    "\n",
    "n0 = 784       # widths of layers\n",
    "n1 = 200\n",
    "n2 = 100\n",
    "n3 = 10\n",
    "\n",
    "eta = 0.01       # learning rate parameter\n",
    "epsinit = 0.01   # magnitude of initial conditions for synaptic weights\n",
    "\n",
    "W1 = epsinit*randn(Float32,n1,n0)\n",
    "W2 = epsinit*randn(Float32,n2,n1)\n",
    "W3 = epsinit*randn(Float32,n3,n2)\n",
    "\n",
    "b1 = epsinit*randn(Float32,n1,1)\n",
    "b2 = epsinit*randn(Float32,n2,1)\n",
    "b3 = epsinit*randn(Float32,n3,1)\n",
    "\n",
    "tmax = 600000       # maximum number of minibatch updates\n",
    "tshow = 1000         # how often to pause (# of minibatches) for visualization\n",
    "\n",
    "errsq = zeros(tmax)\n",
    "errcl = zeros(tmax);\n",
    "errclvalidate = zeros(div(tmax,tshow))\n",
    "\n",
    "# preprocess training set\n",
    "train, trainlabels = traindata()\n",
    "train = convert(Array{Float32,2},train)\n",
    "train = train/255.0\n",
    "trainlabels[trainlabels .==0] = 10\n",
    "trainlabels = convert(Array{Int64,1},trainlabels)\n",
    "\n",
    "# separate out validation set\n",
    "mtotal = size(train,2)    # total number of examples in original training set\n",
    "mvalidate = 10000         # desired size of validation set\n",
    "mtrain = mtotal - mvalidate    # remaining examples will be new training set\n",
    "srand(2017)    # seed the random number generator so that validation set is reproducible\n",
    "ind = randperm(mtotal)\n",
    "validate = train[:,ind[end-mvalidate+1:end]]\n",
    "validatelabels = trainlabels[ind[end-mvalidate+1:end]]\n",
    "train = train[:,ind[1:mtrain]]\n",
    "trainlabels = trainlabels[ind[1:mtrain]]\n",
    "\n",
    "batchsize = 32     # minibatch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t = 1:tmax     # time in number of minibatches\n",
    "    batchindices = ceil(Int,mtrain*rand(batchsize))   # random minibatch\n",
    "    x0 = train[:,batchindices]\n",
    "    batchlabels = trainlabels[batchindices]\n",
    "    y = -ones(Float32,10,batchsize)              # appropriate for tanh\n",
    "#    y = zeros(Float32,10,batchsize)               # appropriate for logistic function\n",
    "    for j in zip(batchlabels,1:batchsize)\n",
    "        y[j...] = 1\n",
    "    end\n",
    "\n",
    "    # forward pass   \n",
    "    x1 = f(W1*x0 .+ b1)\n",
    "    x2 = f(W2*x1 .+ b2)\n",
    "    x3 = f(W3*x2 .+ b3)\n",
    "    # error computation\n",
    "    errsq[t] = sum((y-x3).^2)/batchsize\n",
    "    errcl[t] = mean(float(map(indmax,[x3[:,i] for i=1:batchsize]) .!= batchlabels))\n",
    "    delta3 = (y-x3).*df(x3)\n",
    "    # backward pass\n",
    "    delta2 = (W3'*delta3).*df(x2)\n",
    "    delta1 = (W2'*delta2).*df(x1)\n",
    "\n",
    "#    W3 += (eta/batchsize)*delta3*x2'\n",
    "#    W2 += (eta/batchsize)*delta2*x1'\n",
    "#    W1 += (eta/batchsize)*delta1*x0'\n",
    "    # following is equivalent to but faster than the above weight updates\n",
    "    BLAS.gemm!('N','T',Float32(eta/batchsize),delta3,x2,1.0f0,W3)\n",
    "    BLAS.gemm!('N','T',Float32(eta/batchsize),delta2,x1,1.0f0,W2)\n",
    "    BLAS.gemm!('N','T',Float32(eta/batchsize),delta1,x0,1.0f0,W1)\n",
    "\n",
    "    b3 += (eta/batchsize)*sum(delta3,2)\n",
    "    b2 += (eta/batchsize)*sum(delta2,2)\n",
    "    b1 += (eta/batchsize)*sum(delta1,2)\n",
    "    \n",
    "    if rem(t,tshow) == 0    # visualization every tshow steps\n",
    "        x0 = validate                  # compute error on validation set\n",
    "        x1 = f(W1*x0 .+ b1)\n",
    "        x2 = f(W2*x1 .+ b2)\n",
    "        x3 = f(W3*x2 .+ b3)\n",
    "        errclvalidate[div(t,tshow)] = mean(float(map(indmax,[x3[:,i] for i=1:mvalidate]) .!= validatelabels))       \n",
    "        avgerrsq = mean(reshape(errsq[1:t],tshow,div(t,tshow)),1)'\n",
    "        avgerrcl = mean(reshape(errcl[1:t],tshow,div(t,tshow)),1)'\n",
    "        IJulia.clear_output(true)\n",
    "        plot(\n",
    "            plot(avgerrsq,\n",
    "                ylabel = \"sq err\", \n",
    "                ylim = (0.001,4),\n",
    "                yscale = :log10\n",
    "                ), \n",
    "            plot([avgerrcl, errclvalidate[1:div(t,tshow)]],\n",
    "                ylabel = \"class err\", \n",
    "                ylim = (0.001,1),\n",
    "                yscale = :log10,\n",
    "                title = @sprintf(\"t=%d\",t),\n",
    "                xlabel = @sprintf(\"x%d minibatches\",tshow)\n",
    "                ), \n",
    "            plot([avgerrcl, errclvalidate[1:div(t,tshow)]],\n",
    "                ylabel = \"class err\", \n",
    "                ylim = (0,0.1),\n",
    "                title = @sprintf(\"t=%d\",t),\n",
    "                xlabel = @sprintf(\"x%d minibatches\",tshow)\n",
    "                ), \n",
    "            histogram(x1[:], xlabel = \"x1\"),\n",
    "            histogram(x2[:], xlabel = \"x2\"),\n",
    "            histogram(x3[:], xlabel = \"x3\")\n",
    "            ) |> display\n",
    "        sleep(0.01)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
