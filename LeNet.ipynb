{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roughly patterned after LeNet-5\n",
    "max instead of average pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FastConv` package provides a faster alternative to the built-in `conv` and `conv2` functions.  Install with `Pkg.clone(\"https://github.com/aamini/FastConv.jl.git\")` before running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using FastConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function FastConv.fastconv(A, B, shape::String)   # extend to accept \"full\" or \"valid\" as an third argument\n",
    "    if shape == \"full\"\n",
    "        return FastConv.fastconv(A,B)\n",
    "    elseif shape == \"valid\"\n",
    "        ranges = [ min(a,b):max(a,b) for (a,b) in zip(size(A),size(B)) ]\n",
    "        return FastConv.fastconv(A,B)[ranges...]\n",
    "    else\n",
    "        error(\"shape must be full or valid\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "gr(size=(600,600),legend=:none)\n",
    "\n",
    "# function for displaying a stack of images\n",
    "# imgstack is mxnxp array that contains p images, each of which is mxn \n",
    "function montage(imgstack)\n",
    "    plot(\n",
    "        [heatmap(imgstack[:,:,i]) for i=1:size(imgstack,3)]...,\n",
    "        legend=:none, axis=nothing     # options necessary to get nice spacing of the images\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function maxpool(images)\n",
    "    # 2x2 max pooling for set of images\n",
    "    # returns MAXIMA, WINNERS\n",
    "    # MAXIMA 2x smaller image, maximum of each 2x2 patch\n",
    "    # WINNERS 2x smaller image, argmax (1..4) of each 2x2 patch\n",
    "\n",
    "    m, n, k = size(images)  # mxn images, k of them\n",
    "    # reshape to 2 x m/2 x 2 x n/2 x k\n",
    "    maxima, winners = findmax(reshape(images, 2, div(m,2), 2, div(n,2), k), (1,3))\n",
    "    return squeeze(maxima,(1,3)), squeeze(winners,(1,3))\n",
    "end\n",
    "\n",
    "function maxpoolback(delta_out, winners)\n",
    "    # backprop through 2x2 max pooling\n",
    "    #\n",
    "    # DELTA_IN image, deltas\n",
    "    # DELTA_OUT 2x smaller image, deltas\n",
    "    # WINNERS 2x smaller image, argmax (1..4) of each 2x2 patch\n",
    "\n",
    "    m, n, k = size(delta_out);  # mxn images, k of them\n",
    "    delta_in = zeros(Float32,2*m,2*n,k)\n",
    "\n",
    "    delta_in[winners] = delta_out\n",
    "    return delta_in\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using MNIST\n",
    "\n",
    "train, trainlabels = traindata()\n",
    "train = reshape(train, 28, 28, size(train,2))/255.0\n",
    "train = convert(Array{Float32}, train)\n",
    "trainlabels = convert(Array{Int64},trainlabels)\n",
    "trainlabels[trainlabels .== 0] = 10;  # tenth output signals a zero\n",
    "niter = size(train, 3);  # number of training examples\n",
    "nepoch = 10;  # number of epochs through training set\n",
    "\n",
    "#f(x) = max(x,0)\n",
    "#df(y) = float(y.>0)\n",
    "\n",
    "f(x) = tanh(x)\n",
    "df(y) = 1. - y.*y\n",
    "\n",
    "epsinit = 0.1;   # scale of weight initialization\n",
    "eta = 0.01;  # learning rate parameter\n",
    "\n",
    "# initialize two convolution layers \n",
    "n1 = 6; n2 = 16;   # numbers of feature maps\n",
    "w1 = epsinit*randn(Float32,5,5,n1);     # n1 kernels\n",
    "w2 = epsinit*randn(Float32,5,5,n2,n1);  # n2 x n1 kernels\n",
    "\n",
    "x0 = zeros(Float32, 32, 32);     # input image\n",
    "x1 = zeros(Float32, 28, 28, n1);   # valid convolution by w1 reduces image size by 4\n",
    "x1p = zeros(Float32, 14, 14, n1);  # pooling reduces image size by 2x\n",
    "x2 = zeros(Float32, 10, 10, n2);   # convolution by w2 reduces image size by 4\n",
    "x2p = zeros(Float32, 5, 5, n2);    # pooling reduces image size by 2x\n",
    "\n",
    "# initialize three fully connected layers\n",
    "n3 = 120; n4 = 84; n5 = 10              # number of neurons per layer\n",
    "W3 = epsinit*randn(Float32,n3,length(x2p[:]))   # 2D organization of x2p is discarded\n",
    "W4 = epsinit*randn(Float32,n4,n3)\n",
    "W5 = epsinit*randn(Float32,n5,n4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tic()\n",
    "for iepoch = 1:nepoch\n",
    "    errsq = zeros(niter)  # to monitor learning curve during epoch\n",
    "    errcl = zeros(niter)\n",
    "    for iter = 1:niter\n",
    "        # zero pad 28x28 image to make it 32x32\n",
    "        x0 = zeros(Float32, 32,32);\n",
    "        x0[3:30,3:30] = train[:,:,iter]\n",
    "\n",
    "        for i = 1:n1\n",
    "            x1[:,:,i] = fastconv(x0, w1[:,:,i], \"valid\"); \n",
    "        end\n",
    "        x1 = f(x1)\n",
    "        x1p, x1w = maxpool(x1)\n",
    " \n",
    "        x2 = zeros(Float32,size(x2));  # initialize to zero for accumulation\n",
    "        for i = 1:n2\n",
    "            for j = 1:n1\n",
    "                x2[:,:,i] += fastconv(x1p[:,:,j], w2[:,:,i,j], \"valid\");\n",
    "            end\n",
    "        end\n",
    "        x2 = f(x2); \n",
    "        x2p, x2w = maxpool(x2)\n",
    " \n",
    "        # discard 2D organization of x2p by reshaping to x2p(:)\n",
    "        x3 = f(W3*x2p[:])\n",
    "        x4 = f(W4*x3)\n",
    "        x5 = f(W5*x4)\n",
    "\n",
    "        prediction = indmax(x5);\n",
    "        errcl[iter] = float(prediction != trainlabels[iter]);\n",
    "        # backward pass\n",
    "        d = -ones(Float32, n5,1); d[trainlabels[iter]] = 1;  # output vector\n",
    "        err = d - x5; \n",
    "        errsq[iter] = sum(err.*err)\n",
    "        delta5 = err.*df(x5);\n",
    "        delta4 = (W5'*delta5).*df(x4)\n",
    "        delta3 = (W4'*delta4).*df(x3)\n",
    "        delta2p = W3'*delta3\n",
    "        delta2p = reshape(delta2p, size(x2p))  # restore 2D organization\n",
    "        delta2 = maxpoolback(delta2p, x2w).*df(x2)\n",
    "        delta1p = zeros(Float32,size(x1p))\n",
    "        for j = 1:n1\n",
    "            for i = 1:n2\n",
    "                delta1p[:,:,j] += fastconv(delta2[:,:,i], w2[end:-1:1,end:-1:1,i,j], \"full\")\n",
    "            end\n",
    "        end\n",
    "        delta1 = maxpoolback(delta1p, x1w).*df(x1)\n",
    "\n",
    "        # weight updates\n",
    "        W5 += eta*delta5*x4'\n",
    "        W4 += eta*delta4*x3'\n",
    "        W3 += eta*delta3*x2p[:]'\n",
    "        for i = 1:n2\n",
    "            for j = 1:n1\n",
    "                w2[:,:,i,j] += eta*fastconv(x1p[end:-1:1,end:-1:1,j], delta2[:,:,i], \"valid\")\n",
    "            end\n",
    "        end\n",
    "        for i = 1:n1\n",
    "            w1[:,:,i] += eta*fastconv(x0[end:-1:1,end:-1:1], delta1[:,:,i], \"valid\")\n",
    "        end\n",
    "        if rem(iter,500) == 0\n",
    "            toc()\n",
    "            tic()\n",
    "            IJulia.clear_output(true)\n",
    "            plot(\n",
    "                plot(cumsum(errsq[1:iter])./(1:iter),\n",
    "                    ylabel=\"sq err\"\n",
    "                ),\n",
    "                plot(cumsum(errcl[1:iter])./(1:iter),\n",
    "                    ylabel = \"cl err\", \n",
    "                    title = @sprintf(\"epoch=%d, iter=%d\",iepoch,iter)\n",
    "                ),\n",
    "                bar(x5, xlabel=\"x5\"),\n",
    "                histogram(x4, xlabel=\"x4\"),\n",
    "                histogram(x3, xlabel=\"x3\"),\n",
    "                heatmap(x0, yflip=true),\n",
    "                plot(\n",
    "                    [heatmap(w1[:,:,i],\n",
    "                             axis = nothing, \n",
    "                             color = :grays, \n",
    "                             yflip = true\n",
    "                             ) for i = 1:n1]...), \n",
    "                layout = @layout [a b c; d e f; g{0.5h}]\n",
    "            ) |> display\n",
    "            sleep(0.01)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
