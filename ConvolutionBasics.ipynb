{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Julia's built-in `conv` function only does \"full\" convolution. Below we extend it to do either \"full\" or \"valid.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extend conv to accept \"full\" or \"valid\" as an third argument\n",
    "function Base.conv(A, B, shape::String)   \n",
    "    if shape == \"full\"\n",
    "        return Base.conv(A,B)\n",
    "    elseif shape == \"valid\"\n",
    "        range = [ min( length(A), length(B) ):max( length(A), length(B) ) ]\n",
    "        return Base.conv(A,B)[range...]\n",
    "    else\n",
    "        error(\"shape must be either full or valid\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1. Complete the following code to implement 1D \"full\" convolution. You need only fill in the question marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition conv_full(Any, Any) in module Main at In[14]:2 overwritten at In[36]:3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc\"\"\"\n",
    "`CONV_FULL` - 1D \"full\" convolution\n",
    "\n",
    "    R = CONV_FULL(W, S) \n",
    "\n",
    "* `W`: 1D array\n",
    "* `S`: 1D array\n",
    "* `R`: \"full\" convolution of W and S\n",
    "\"\"\"\n",
    "function conv_full(w,s)\n",
    "    r = zeros(?)\n",
    "    for i = 1:?\n",
    "        for j = 1:?\n",
    "            r[?] += w[i]*s[j]  \n",
    "        end\n",
    "    end\n",
    "    return r\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your function by comparing with the built-in `conv` function. The output of the following should be true, if your code is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: conv_full not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: conv_full not defined",
      ""
     ]
    }
   ],
   "source": [
    "a = rand(10)\n",
    "b = rand(3)\n",
    "isapprox(conv_full(a,b), conv(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2. Complete the following code to implement 2D \"full\" convolution. You need only fill in the question marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition conv2_full(Any, Any) in module Main at In[34]:2 overwritten at In[35]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc\"\"\"\n",
    "`CONV2_FULL` - 2D \"full\" convolution\n",
    "\n",
    "    R = CONV2_FULL(W, S) \n",
    "\n",
    "* `W`: 2D array\n",
    "* `S`: 2D array\n",
    "* `R`: \"full\" convolution of W and S\n",
    "\"\"\"\n",
    "function conv2_full(w,s)\n",
    "    wsize1, wsize2 = size(w)\n",
    "    ssize1, ssize2 = size(s)\n",
    "    r = zeros(?)\n",
    "    for i1 = 1:?\n",
    "        for i2 = 1:?\n",
    "            for j1 = 1:?\n",
    "                for j2 = 1:?\n",
    "                    r[?, ?] += w[i1, i2] * s[j1, j2]\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return r\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your function by comparing with the built-in `conv2` function. The output of the following should be true, if your code is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = rand(10,6)\n",
    "b = rand(3,2)\n",
    "isapprox(conv2_full(a,b), conv2(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3. In class you learned that 1D convolution is equivalent to multiplication by a Toeplitz matrix, where the size of the matrix depends on the length of the input signal. Complete the following code to construct the matrix. You need only fill in the question marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition convmtx(Any, Any) in module Main at In[15]:12 overwritten at In[17]:12.\n",
      "WARNING: Method definition convmtx(Any, Any, Any) in module Main at In[15]:12 overwritten at In[17]:12.\n",
      "\u001b[1m\u001b[31mWARNING: replacing docs for 'convmtx :: Union{Tuple{Any,Any,Any},Tuple{Any,Any}}' in module 'Main'.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "convmtx"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc\"\"\"\n",
    "`CONVMTX` - 1D convolution matrix\n",
    "\n",
    "    MTX = CONVMTX(KERNEL, INSIZE) \n",
    "\n",
    "* `KERNEL`: kernel of the convolution\n",
    "* `INSIZE`: length of the input signal\n",
    "* `MTX`: multiplication by MTX is equivalent to convolution by KERNEL\n",
    "\"\"\"\n",
    "function convmtx(kernel, insize, shape = \"full\")\n",
    "\n",
    "    kernelsize = length(kernel)\n",
    "    outsize = ?\n",
    "    mtx = zeros(outsize, insize)\n",
    "\n",
    "    for i = 1:insize\n",
    "        mtx[ ? + (1:?), i ] = kernel\n",
    "    end\n",
    "\n",
    "    if shape == \"valid\"\n",
    "        mtx = mtx[ ?:?, :]\n",
    "    end\n",
    "\n",
    "    return mtx\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that multiplication by your matrix is equivalent to convolution. The output of the following should be true, if your code is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = rand(3)\n",
    "sig = rand(7)\n",
    "isapprox(convmtx(kernel,length(sig),\"full\")*sig, conv(kernel,sig,\"full\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isapprox(convmtx(kernel,length(sig),\"valid\")*sig, conv(kernel,sig,\"valid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following illustrates that the transpose of a convolution matrix is equal to a convolution matrix with a flipped kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = collect(1:3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convmtx(kernel,5,\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convmtx(kernel[end:-1:1],3, \"full\")     # the kernel is flipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no coding to do here. Just verify for yourself that the above two matrices are transposes of each other.  Note that transpose changes valid to full, and vice versa. This is why the backward pass for a convolutional net contains flipped kernels. These are equivalent to the transposed matrices in the backward pass for a neural net."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
